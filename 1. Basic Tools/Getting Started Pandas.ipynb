{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PANDAS\n",
    "Visit the official website of __Pandas__ for more content in __[this link](https://pandas.pydata.org)__\n",
    "<img src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/03/pandas.jpg\"\n",
    "alt=\"pandas\" title=\"Pandas\" height=\"400\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import data from CSV file\n",
    "pd.read_csv(filename)\n",
    "\n",
    "# Import data from a delimited text file (like TSV)\n",
    "pd.read_table(filename)\n",
    "\n",
    "# Import data from an Excel file\n",
    "pd.read_excel(filename)\n",
    "\n",
    "# Read from a SQL table/database\n",
    "pd.read_sql(query, connection_object)\n",
    "\n",
    "# Import data from a JSON formatted string, this could be a URL or a file\n",
    "pd.read_json(json_string)\n",
    "\n",
    "# Parse an html URL, string or file and extracts tables to a list of dataframes\n",
    "pd.read_html(url)\n",
    "\n",
    "# Take the content of your clipboard and passes it to read_table()\n",
    "# If you do not know how to copy to your clipboard, I recommend this link\n",
    "# http://ask.xmodulo.com/copy-file-content-clipboard-linux-desktop.html\n",
    "pd.read_clipboard()\n",
    "\n",
    "# From a dict, keys for columns names, values for data as lists\n",
    "pd.DataFrame(var_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a CSV file\n",
    "df.to_csv(filename)\n",
    "\n",
    "# Write to an Excel file\n",
    "df.to_excel(filename)\n",
    "\n",
    "# Write to a SQL table\n",
    "df.to_sql(table_name, connection_object)\n",
    "\n",
    "# Write a file in JSON format\n",
    "df.to_json(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful for testing code segments\n",
    "\n",
    "# 5 Columns and 20 rows of random floats\n",
    "pd.DataFrame(np.random.rand(20, 5))\n",
    "\n",
    "# Create a series from an iterable 'my_list'\n",
    "pd.Series(my_list)\n",
    "\n",
    "# Add a date index\n",
    "df.index = pd.date_range('1900/1/30', periods=df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing and inspecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First n rowa of the DataFrame\n",
    "df.head(n)\n",
    "\n",
    "# Last n rows of the DataFrame\n",
    "df.tail(n)\n",
    "\n",
    "# Number of rows and columns\n",
    "df.shape()\n",
    "\n",
    "# Index, Datatype and Memory information\n",
    "df.info()\n",
    "\n",
    "# Summary statistics for numerical columns\n",
    "df.describe()\n",
    "\n",
    "# View unique values and counts\n",
    "s.value_count(dropna=False)\n",
    "\n",
    "# Unique values and counts for all columns\n",
    "df.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns columns with label col as Series\n",
    "df[col]\n",
    "\n",
    "# Returns columns as a new DataFrame\n",
    "df[[col1, col2]]\n",
    "\n",
    "# Selection by Position\n",
    "s.iloc[0]\n",
    "\n",
    "# Selection by index\n",
    "s.loc['index_one']\n",
    "\n",
    "# First row\n",
    "df.iloc[0, :]\n",
    "\n",
    "# First element of first column\n",
    "df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df.columns = ['a', 'b', 'c']\n",
    "\n",
    "# Checks for null Values, Returns Boolean Array\n",
    "pd.isnull()\n",
    "\n",
    "# Opposite of pd.isnull()\n",
    "pd.notnull()\n",
    "\n",
    "# Drop all columns that contain null values\n",
    "df.dropna(axis=1)\n",
    "\n",
    "# Drop all rows have less than n non null values\n",
    "df.dropna(axis=1, thresh=n)\n",
    "\n",
    "# Replace all null values with x\n",
    "df.fillna(x)\n",
    "\n",
    "# Replace all null values with the mean*mean can be replace with almost any function from the statistics section)\n",
    "s.fillna(s.mean())\n",
    "\n",
    "# Convert the datatype of  the series to float\n",
    "s.astype(float)\n",
    "\n",
    "# Replace all values equal to 1 with 'one'\n",
    "s.replace(1, 'one')\n",
    "\n",
    "# Replace all 1 with 'one' and 3 with 'three'\n",
    "s.replace([1, 3], ['one', 'three'])\n",
    "\n",
    "# Mass renaming of columns\n",
    "df.rename(columns=lambda x: x + 1)\n",
    "\n",
    "# Selective renaming\n",
    "df.rename(columns={'old_name': 'new_name'})\n",
    "\n",
    "# Change the index\n",
    "df.set_index('column_one')\n",
    "\n",
    "# Mass renaming of index\n",
    "df.rename(index=lambda x: x + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter, sort and groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows where the column col is great than 0.5\n",
    "df[df[col] > 0.5]\n",
    "\n",
    "# Rows where 0.7 > col > 0.5\n",
    "df[(df[col] > 0.5) & (df[col] < 0.7)]\n",
    "\n",
    "# Sort values by col1 in ascending order\n",
    "df.sort_values(col1)\n",
    "\n",
    "# Sort values by col2 in descending order\n",
    "df.sort_values(col2, ascending=False)\n",
    "\n",
    "# Sort values by col1 in ascending order then col2 in descending order\n",
    "df.sort_values([col1, col2], ascending=[True, False])\n",
    "\n",
    "# Returns a groupby object for values from one column\n",
    "df.groupby(col)\n",
    "\n",
    "# Returns groupby object for values from multiple columns\n",
    "df.groupby([col1, col2])\n",
    "\n",
    "# Returns the mean of the values in col2, grouped by the values in col1 (mean can be replaced with almost any function from the statistics section)\n",
    "df.groupby(col1)[col2]\n",
    "\n",
    "# Create a pivot table that groups by col1 and calculates the mean of col2 and col3\n",
    "df.pivot_table(index=col1, values=[col2, col3], aggfunc=mean)\n",
    "\n",
    "# Find the average across all columns for every unique col1 group\n",
    "df.groupby(col1).agg(np.mean)\n",
    "\n",
    "# Apply the function np.max() acrosss each row\n",
    "nf.apply(np.max, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join and combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the rows in df1 to the end of df2 (columns should be identical)\n",
    "df1.append(df2)\n",
    "\n",
    "# Add the columns in df1 to the end of df2 (rows should be identical)\n",
    "pd.concat([df1, df2], axis=1)\n",
    "\n",
    "# SQL-style join the columns in df1 with the columns on df2 where\n",
    "# the rows for col have identical values.\n",
    "# How can be one of 'left', 'right', 'outer', 'inner'\n",
    "df1.join(df2, on=col1, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These can all be applied to a series as well\n",
    "\n",
    "# Summary statistics for numerical columns\n",
    "df.describe()\n",
    "\n",
    "# Returns the mean of all columns\n",
    "df.mean()\n",
    "\n",
    "# Returns the correlation between columns in a DataFrame\n",
    "df.corr()\n",
    "\n",
    "# Returns the number of non-null values in each DataFrame columns\n",
    "df.count()\n",
    "\n",
    "# Rethr tbe highest value in each column\n",
    "df.max()\n",
    "\n",
    "# Returns the lowest value in each columns\n",
    "df.min()\n",
    "\n",
    "# Return the median of each column\n",
    "df.median()\n",
    "\n",
    "# Returns the standard deviation of each column\n",
    "df.std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
